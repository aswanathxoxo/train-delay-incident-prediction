# train-delay-incident-prediction

# ğŸ“˜ **Train Delay Incident Prediction (TNR) â€“ Machine Learning System**

MSc Applied Artificial Intelligence â€“ 7DATA001W**
Author:** Aswanath Jayanath Sumi â€“ 21660070


## â­ **Project Overview**

This project builds a complete Machine Learning system to **predict train incidents** before they occur, helping TransNational Railways (TNR) reduce avoidable delays and operational costs.

The workflow includes:

* Data ingestion
* Preprocessing (cleaning, missing value imputation, outlier handling)
* Feature engineering
* Model training & evaluation
* Hyperparameter tuning
* MLflow experiment tracking
* Model saving
* API deployment (FastAPI)

The final deployed model is a **Tuned XGBoost Classifier**, achieving the best performance in detecting incidents.

---

## ğŸ“ **Project Structure**




ML_COURSEWORK
â”‚
â”œâ”€â”€ data/
â”‚     â””â”€â”€ TNR_Data.csv
â”‚
â”œâ”€â”€ mlruns/                         <-- MLflow experiment tracking folder
â”‚
â”œâ”€â”€ model_artifacts/
â”‚     â”œâ”€â”€ tuned_xgboost_v1_0/       <-- your saved tuned model (MLflow format)
â”‚     â””â”€â”€ model.pkl                 <-- (likely manually exported)
â”‚
â”œâ”€â”€ Notebook/                       <-- Jupyter notebook outputs
â”‚     â””â”€â”€ api.py                          <-- FastAPI app for model deployment
â”œâ”€â”€ requirements.txt





## ğŸ§¹ **Data Preprocessing Summary**

### âœ¦ 1. Missing Value Handling

* `dwell_time` was missing in **6,365 rows**.
* Missingness was identified as **MAR (Missing At Random)**.
* Imputed using **Linear Regression** with strong predictors:

  * `on_train_bookings`
  * `on_train_forecast`

### âœ¦ 2. Outlier Detection

* IQR method selected (robust, non-parametric, dataset skewed).
* Outliers capped only for relevant features.

### âœ¦ 3. Feature Engineering

* OneHotEncoding for categorical features
* StandardScaler for numeric features
* Fully integrated inside **ColumnTransformer**
* Avoids leakage and ensures reproducibility

---

## ğŸ¤– **Model Training**

Three baseline models were implemented:

XGBoost performed best, so it was tuned using:

* **RandomizedSearchCV**
* 5-fold **Stratified CV**
* Scoring metric: **F1-score**



## ğŸ“Š **MLflow Experiment Tracking**

MLflow is used for:

* Logging hyperparameters
* Logging accuracy, precision, recall, F1
* Saving the entire preprocessing + model pipeline
* Comparing baseline vs tuned models

### Start MLflow UI:

```
% mlflow ui --backend-store-uri mlruns
```

Then open:
ğŸ‘‰ [http://127.0.0.1:5000/](http://127.0.0.1:5000/)

---

## ğŸ“¦ **Saved Model (for Deployment)**

The final tuned model is saved at:

```
model_artifacts/tuned_xgboost_v1.0/
```


## ğŸŒ **API Deployment (FastAPI)**

The file **api.py** loads the saved model and exposes a prediction endpoint.

### Run the API:

```
uvicorn api:app --reload --host 127.0.0.1 --port 8001
```

### Example Request (POST)

```
POST http://127.0.0.1:8001/predict
Content-Type: application/json
```

Example JSON:

```json
{
  "origin": "DON",
  "dest": "KGX",
  "temp": 12.5,
  "rain_1h": 0.2,
  "dwell_time": 3.5,
  ...
}
```

### Example Response:

```json
{
  "prediction": 1,
  "message": "Incident likely"
}
```

---

## ğŸ”§ **Installation**

### 1. Create virtual environment

```
python3 -m venv .venv
source .venv/bin/activate
```

### 2. Install dependencies

```
pip install -r requirements.txt
```

### 3. Run notebook or API

---

## ğŸ§ª **Testing**

A basic functional test ensures correct output shape:

```python
assert predictions.ndim == 1  
assert len(predictions) == len(X_input)
```

Test passed âœ”ï¸

---

## ğŸ“ **Key Technologies Used**

* Python
* Scikit-learn
* XGBoost
* Pandas & NumPy
* FastAPI
* MLflow
* Matplotlib / Seaborn

---

## ğŸ¯ Final Remarks

This project implements a complete ML lifecycle:

âœ” Data processing
âœ” Feature engineering
âœ” Baseline & tuned models
âœ” Validation & visualisation
âœ” MLflow logging
âœ” Deployment-ready API

The **Tuned XGBoost model** is the final chosen solution due to superior F1 performance and strong ROC-AUC results.

---





































































